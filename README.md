# Sematic-Cache-Gateway
The Semantic Cache Gateway is a high-performance middleware service designed to optimize Large Language Model (LLM) interactions. By sitting between the client and the LLM provider (e.g., OpenAI), the gateway intercepts requests and utilizes Vector Similarity Search to serve cached responses for semantically similar queries.
